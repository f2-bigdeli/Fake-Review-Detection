{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Deep Learning Model Development \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, SimpleRNN, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.5353 - loss: 0.7089 - precision_1: 0.5314 - recall_1: 0.8242 - val_accuracy: 0.6161 - val_loss: 0.6762 - val_precision_1: 0.6279 - val_recall_1: 0.5875\n",
      "Epoch 2/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 240ms/step - accuracy: 0.6869 - loss: 0.6218 - precision_1: 0.6991 - recall_1: 0.6613 - val_accuracy: 0.6276 - val_loss: 0.6627 - val_precision_1: 0.6250 - val_recall_1: 0.6601\n",
      "Epoch 3/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 240ms/step - accuracy: 0.7801 - loss: 0.4948 - precision_1: 0.8032 - recall_1: 0.7421 - val_accuracy: 0.6367 - val_loss: 0.7154 - val_precision_1: 0.6166 - val_recall_1: 0.7459\n",
      "Epoch 4/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 242ms/step - accuracy: 0.8483 - loss: 0.3830 - precision_1: 0.8478 - recall_1: 0.8478 - val_accuracy: 0.6247 - val_loss: 0.8094 - val_precision_1: 0.6337 - val_recall_1: 0.6139\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.6428 - loss: 0.6580 - precision_1: 0.6040 - recall_1: 0.7039\n",
      "Test Loss: 0.6499, Test Accuracy: 0.6475, Test Precision: 0.6243, Test Recall: 0.6975\n",
      "Test F1 Score: 0.6589\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv(\"modified_dataset.csv\")\n",
    "\n",
    "# Prepare the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['LABEL'])\n",
    "\n",
    "# Prepare the text data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['REVIEW_TEXT'])\n",
    "sequences = tokenizer.texts_to_sequences(df['REVIEW_TEXT'])\n",
    "X = pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "lstm_model = Sequential([\n",
    "    Input(shape=(200,)),\n",
    "    Embedding(input_dim=10000, output_dim=64),\n",
    "    LSTM(50, return_sequences=True),  \n",
    "    Dropout(0.3),\n",
    "    LSTM(50),  \n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "])\n",
    "\n",
    "# Compile the model with additional metrics\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Setup early stopping\n",
    "early_stopping_lstm = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)  # Aggressive early stopping\n",
    "\n",
    "# Train the model with early stopping\n",
    "lstm_model_history = lstm_model.fit(\n",
    "    X_train, y_train, epochs=20, validation_split=0.2, batch_size=64,  \n",
    "    callbacks=[early_stopping_lstm]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set to get the performance metrics\n",
    "test_loss, test_accuracy, test_precision, test_recall = lstm_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "# Calculate the F1-score\n",
    "test_f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "print(f\"Test F1 Score: {test_f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 65ms/step - accuracy: 0.5443 - loss: 0.6861 - precision_2: 0.5384 - recall_2: 0.7706 - val_accuracy: 0.6429 - val_loss: 0.6330 - val_precision_2: 0.6951 - val_recall_2: 0.4856\n",
      "Epoch 2/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.7317 - loss: 0.5458 - precision_2: 0.7442 - recall_2: 0.6953 - val_accuracy: 0.6520 - val_loss: 0.6240 - val_precision_2: 0.6137 - val_recall_2: 0.7747\n",
      "Epoch 3/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 62ms/step - accuracy: 0.8265 - loss: 0.3999 - precision_2: 0.8276 - recall_2: 0.8232 - val_accuracy: 0.6539 - val_loss: 0.7069 - val_precision_2: 0.6135 - val_recall_2: 0.7870\n",
      "Epoch 4/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.9101 - loss: 0.2464 - precision_2: 0.9088 - recall_2: 0.9145 - val_accuracy: 0.6467 - val_loss: 0.8611 - val_precision_2: 0.6102 - val_recall_2: 0.7521\n",
      "Epoch 5/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.9630 - loss: 0.1125 - precision_2: 0.9605 - recall_2: 0.9665 - val_accuracy: 0.6642 - val_loss: 1.1053 - val_precision_2: 0.6734 - val_recall_2: 0.6152\n",
      "Epoch 6/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9874 - loss: 0.0419 - precision_2: 0.9877 - recall_2: 0.9874 - val_accuracy: 0.6587 - val_loss: 1.5239 - val_precision_2: 0.6446 - val_recall_2: 0.6811\n",
      "Epoch 7/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.9957 - loss: 0.0165 - precision_2: 0.9953 - recall_2: 0.9964 - val_accuracy: 0.6529 - val_loss: 2.2456 - val_precision_2: 0.6563 - val_recall_2: 0.6070\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6434 - loss: 0.6285 - precision_2: 0.5925 - recall_2: 0.7767\n",
      "Test Loss: 0.6240, Test Accuracy: 0.6520, Test Precision: 0.6137, Test Recall: 0.7747\n",
      "Test F1 Score: 0.6849\n"
     ]
    }
   ],
   "source": [
    "# CNN-LSTM Model Setup\n",
    "cnn_lstm_model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=50),\n",
    "    Conv1D(filters=64, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=4),\n",
    "    LSTM(100),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiling the CNN-LSTM model\n",
    "cnn_lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping_cnn_lstm = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Training the CNN-LSTM model\n",
    "cnn_lstm_model_history = cnn_lstm_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stopping_cnn_lstm])\n",
    "\n",
    "# Evaluating the model on the test set to get the test performance metrics\n",
    "test_loss, test_accuracy, test_precision, test_recall = cnn_lstm_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "# Calculate the F1-score\n",
    "test_f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "print(f\"Test F1 Score: {test_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 164ms/step - accuracy: 0.5091 - loss: 0.6934 - precision_3: 0.5087 - recall_3: 0.5236 - val_accuracy: 0.5646 - val_loss: 0.6788 - val_precision_3: 0.5299 - val_recall_3: 0.9403\n",
      "Epoch 2/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 160ms/step - accuracy: 0.6517 - loss: 0.6308 - precision_3: 0.6467 - recall_3: 0.7039 - val_accuracy: 0.6250 - val_loss: 0.6456 - val_precision_3: 0.6276 - val_recall_3: 0.5792\n",
      "Epoch 3/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 160ms/step - accuracy: 0.7697 - loss: 0.5097 - precision_3: 0.7683 - recall_3: 0.7738 - val_accuracy: 0.6293 - val_loss: 0.6678 - val_precision_3: 0.5930 - val_recall_3: 0.7510\n",
      "Epoch 4/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 160ms/step - accuracy: 0.8231 - loss: 0.4016 - precision_3: 0.8122 - recall_3: 0.8266 - val_accuracy: 0.6286 - val_loss: 0.7182 - val_precision_3: 0.6018 - val_recall_3: 0.7058\n",
      "Epoch 5/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 161ms/step - accuracy: 0.9028 - loss: 0.2554 - precision_3: 0.9005 - recall_3: 0.9082 - val_accuracy: 0.6268 - val_loss: 0.8435 - val_precision_3: 0.6136 - val_recall_3: 0.6224\n",
      "Epoch 6/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - accuracy: 0.9417 - loss: 0.1606 - precision_3: 0.9385 - recall_3: 0.9493 - val_accuracy: 0.6278 - val_loss: 0.9481 - val_precision_3: 0.6144 - val_recall_3: 0.6245\n",
      "Epoch 7/20\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 160ms/step - accuracy: 0.9639 - loss: 0.1129 - precision_3: 0.9571 - recall_3: 0.9714 - val_accuracy: 0.6417 - val_loss: 1.0899 - val_precision_3: 0.6366 - val_recall_3: 0.6091\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.6227 - loss: 0.6445 - precision_3: 0.6029 - recall_3: 0.5835\n",
      "Test Loss: 0.6456, Test Accuracy: 0.6250, Test Precision: 0.6276, Test Recall: 0.5792\n",
      "Test F1 Score: 0.6025\n"
     ]
    }
   ],
   "source": [
    "# LSTM-RNN Model Setup\n",
    "lstm_rnn_model = Sequential([\n",
    "    Input(shape=(200,)),  \n",
    "    Embedding(input_dim=10000, output_dim=50),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    SimpleRNN(32),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiling the LSTM-RNN model\n",
    "lstm_rnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping_lstm_rnn = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Training the LSTM-RNN model\n",
    "lstm_rnn_model_history = lstm_rnn_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stopping_lstm_rnn])\n",
    "\n",
    "# Evaluate the model on the test set to get the performance metrics\n",
    "test_loss, test_accuracy, test_precision, test_recall = lstm_rnn_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "# Calculate the F1-score\n",
    "test_f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "print(f\"Test F1 Score: {test_f1_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
