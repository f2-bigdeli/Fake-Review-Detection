{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Data Cleaning & Dataset Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             category  rating label  \\\n",
      "0  Home_and_Kitchen_5     5.0    CG   \n",
      "1  Home_and_Kitchen_5     5.0    CG   \n",
      "2  Home_and_Kitchen_5     5.0    CG   \n",
      "3  Home_and_Kitchen_5     1.0    CG   \n",
      "4  Home_and_Kitchen_5     5.0    CG   \n",
      "\n",
      "                                               text_  \n",
      "0  Love this!  Well made, sturdy, and very comfor...  \n",
      "1  love it, a great upgrade from the original.  I...  \n",
      "2  This pillow saved my back. I love the look and...  \n",
      "3  Missing information on how to use it, but it i...  \n",
      "4  Very nice set. Good quality. We have had the s...  \n",
      "   Unnamed: 0  rating  verified PRODUCT_CATEGORY  product_id  \\\n",
      "0           0     4.0       0.0               PC  B00008NG7N   \n",
      "1           1     4.0       1.0         Wireless  B00LH0Y3NM   \n",
      "2           2     4.0       1.0         Wireless  B00LH0Y3NM   \n",
      "3           3     3.0       0.0             Baby  B000I5UZ1Q   \n",
      "4           4     4.0       0.0  Office Products  B003822IRA   \n",
      "\n",
      "               review_title  \\\n",
      "0                    useful   \n",
      "1     New era for batteries   \n",
      "2                        OK   \n",
      "3  doesn't swing very well.   \n",
      "4          Great computing!   \n",
      "\n",
      "                                         review_text  cat_0  cat_1  cat_2  \\\n",
      "0  When least you think so, this product will sav...    0.0    0.0    0.0   \n",
      "1  Lithium batteries are something new introduced...    0.0    0.0    0.0   \n",
      "2  Seems to perform just ok, it's a battery. Came...    0.0    0.0    0.0   \n",
      "3  I purchased this swing for my baby. She is 6 m...    0.0    0.0    1.0   \n",
      "4  I was looking for an inexpensive desk calcolat...    0.0    0.0    0.0   \n",
      "\n",
      "   ...  text_sentiment  text_subjectivity  rating_count  rating_avg  rating1  \\\n",
      "0  ...        0.200000           0.400000         233.0         4.6     0.03   \n",
      "1  ...        0.719226           0.385320         214.0         3.8     0.17   \n",
      "2  ...        0.977778           0.611111         214.0         3.8     0.17   \n",
      "3  ...        0.847143           0.600000         923.0         4.4     0.06   \n",
      "4  ...        0.411458           0.441667       11026.0         4.8     0.01   \n",
      "\n",
      "   rating2  rating3  rating4  rating5  \\\n",
      "0     0.01     0.07     0.07     0.81   \n",
      "1     0.06     0.14     0.11     0.53   \n",
      "2     0.06     0.14     0.11     0.53   \n",
      "3     0.03     0.08     0.07     0.76   \n",
      "4     0.01     0.03     0.10     0.85   \n",
      "\n",
      "                                       product_title  \n",
      "0        Targus PAUK10U Ultra Mini USB Keypad, Black  \n",
      "1  Note 3 Battery : Stalion Strength Replacement ...  \n",
      "2  Note 3 Battery : Stalion Strength Replacement ...  \n",
      "3       Fisher-Price Papasan Cradle Swing, Starlight  \n",
      "4  Casio MS-80B Standard Function Desktop Calculator  \n",
      "\n",
      "[5 rows x 48 columns]\n",
      "   DOC_ID       LABEL  RATING VERIFIED_PURCHASE PRODUCT_CATEGORY  PRODUCT_ID  \\\n",
      "0       1  __label1__       4                 N               PC  B00008NG7N   \n",
      "1       2  __label1__       4                 Y         Wireless  B00LH0Y3NM   \n",
      "2       3  __label1__       3                 N             Baby  B000I5UZ1Q   \n",
      "3       4  __label1__       4                 N  Office Products  B003822IRA   \n",
      "4       5  __label1__       4                 N           Beauty  B00PWSAXAM   \n",
      "\n",
      "                                       PRODUCT_TITLE  \\\n",
      "0        Targus PAUK10U Ultra Mini USB Keypad, Black   \n",
      "1  Note 3 Battery : Stalion Strength Replacement ...   \n",
      "2       Fisher-Price Papasan Cradle Swing, Starlight   \n",
      "3  Casio MS-80B Standard Function Desktop Calculator   \n",
      "4  Shine Whitening - Zero Peroxide Teeth Whitenin...   \n",
      "\n",
      "               REVIEW_TITLE                                        REVIEW_TEXT  \n",
      "0                    useful  When least you think so, this product will sav...  \n",
      "1     New era for batteries  Lithium batteries are something new introduced...  \n",
      "2  doesn't swing very well.  I purchased this swing for my baby. She is 6 m...  \n",
      "3          Great computing!  I was looking for an inexpensive desk calcolat...  \n",
      "4     Only use twice a week  I only use it twice a week and the results are...  \n",
      "   User_id  Product_id  Rating       Date  \\\n",
      "0      923           0       3  12/8/2014   \n",
      "1      924           0       3  5/16/2013   \n",
      "2      925           0       4   7/1/2013   \n",
      "3      926           0       4  7/28/2011   \n",
      "4      927           0       4  11/1/2010   \n",
      "\n",
      "                                              Review  Label  \n",
      "0  The food at snack is a selection of popular Gr...     -1  \n",
      "1  This little place in Soho is wonderful. I had ...     -1  \n",
      "2  ordered lunch for 15 from Snack last Friday. Â...     -1  \n",
      "3  This is a beautiful quaint little restaurant o...     -1  \n",
      "4  Snack is great place for a Â casual sit down l...     -1  \n",
      "  deceptive   hotel  polarity       source  \\\n",
      "0  truthful  conrad  positive  TripAdvisor   \n",
      "1  truthful   hyatt  positive  TripAdvisor   \n",
      "2  truthful   hyatt  positive  TripAdvisor   \n",
      "3  truthful    omni  positive  TripAdvisor   \n",
      "4  truthful   hyatt  positive  TripAdvisor   \n",
      "\n",
      "                                                text  \n",
      "0  We stayed for a one night getaway with family ...  \n",
      "1  Triple A rate with upgrade to view room was le...  \n",
      "2  This comes a little late as I'm finally catchi...  \n",
      "3  The Omni Chicago really delivers on all fronts...  \n",
      "4  I asked for a high floor away from the elevato...  \n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "df1 = pd.read_csv(\"Amazon_1.csv\")\n",
    "df2 = pd.read_csv(\"Amazon_2.csv\")\n",
    "df3 = pd.read_csv(\"Amazon_3.txt\", delimiter=\"\\t\")\n",
    "df4 = pd.read_csv(\"Yelp_1.csv\")\n",
    "df5 = pd.read_csv(\"Hotels.csv\")\n",
    "\n",
    "# Print header of dataframes\n",
    "print(df1.head())\n",
    "print(df2.head())\n",
    "print(df3.head())\n",
    "print(df4.head())\n",
    "print(df5.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 column names: Index(['PRODUCT_CATEGORY', 'RATING', 'LABEL', 'REVIEW_TEXT', 'SOURCE'], dtype='object')\n",
      "df2 column names: Index(['RATING', 'VERIFIED_PURCHASE', 'PRODUCT_CATEGORY', 'REVIEW_TITLE',\n",
      "       'REVIEW_TEXT', 'LABEL', 'PRODUCT_TITLE', 'SOURCE'],\n",
      "      dtype='object')\n",
      "df3 column names: Index(['LABEL', 'RATING', 'VERIFIED_PURCHASE', 'PRODUCT_CATEGORY',\n",
      "       'PRODUCT_TITLE', 'REVIEW_TITLE', 'REVIEW_TEXT', 'SOURCE'],\n",
      "      dtype='object')\n",
      "df4 column names: Index(['RATING', 'REVIEW_TEXT', 'LABEL', 'SOURCE', 'PRODUCT_CATEGORY'], dtype='object')\n",
      "df5 column names: Index(['LABEL', 'PRODUCT_TITLE', 'SOURCE', 'REVIEW_TEXT', 'PRODUCT_CATEGORY'], dtype='object')\n",
      "df1 rows, columns: (40432, 5)\n",
      "df2 rows, columns: (18107, 8)\n",
      "df3 rows, columns: (21000, 8)\n",
      "df4 rows, columns: (359052, 5)\n",
      "df5 rows, columns: (1600, 5)\n",
      "LABEL\n",
      "OR    20215\n",
      "CG    20205\n",
      "Name: count, dtype: int64\n",
      "LABEL\n",
      "0.0    9399\n",
      "1.0    8708\n",
      "Name: count, dtype: int64\n",
      "LABEL\n",
      "__label1__    10500\n",
      "__label2__    10500\n",
      "Name: count, dtype: int64\n",
      "LABEL\n",
      " 1    321880\n",
      "-1     36703\n",
      "Name: count, dtype: int64\n",
      "LABEL\n",
      "deceptive    800\n",
      "truthful     796\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop Unnecessary Columns:\n",
    "df2.drop(columns=['Unnamed: 0', 'product_id', 'cat_0', 'cat_1', 'cat_2', 'cat_3', 'cat_4', 'cat_5', 'cat_6', 'cat_7', 'cat_8', 'cat_9', 'cat_10', 'cat_11', 'cat_12', 'cat_13', 'cat_14', 'cat_15', 'cat_16', 'cat_17', 'cat_18', 'cat_19', 'cat_20', 'cat_21', 'cat_22', 'cat_23', 'cat_24', 'cat_25', 'cat_26', 'cat_27', 'cat_28', 'cat_29', 'text_sentiment', 'text_subjectivity', 'rating_count', 'rating_avg', 'rating1', 'rating2', 'rating3', 'rating4', 'rating5'], inplace=True)\n",
    "df3.drop(columns=['DOC_ID', 'PRODUCT_ID'], inplace=True)\n",
    "df4.drop(columns=['User_id', 'Product_id', 'Date'], inplace=True)\n",
    "df5.drop(columns=['polarity'], inplace=True)\n",
    "\n",
    "# Rename columns to have consistent names across datasets\n",
    "df1.rename(columns={'category' : 'PRODUCT_CATEGORY', 'text_': 'REVIEW_TEXT', 'label': 'LABEL'}, inplace=True)\n",
    "df2.rename(columns={'review_text': 'REVIEW_TEXT', 'product_title': 'PRODUCT_TITLE', 'verified': 'VERIFIED_PURCHASE', 'label': 'LABEL'}, inplace=True)\n",
    "df4.rename(columns={'Review': 'REVIEW_TEXT', 'Label': 'LABEL'}, inplace=True)\n",
    "df5.rename(columns={'text': 'REVIEW_TEXT', 'hotel': 'PRODUCT_TITLE', 'deceptive': 'LABEL'}, inplace=True)\n",
    "\n",
    "# Add SOURCE column\n",
    "df1['SOURCE'] = 'AMAZON'\n",
    "df2['SOURCE'] = 'AMAZON'\n",
    "df3['SOURCE'] = 'AMAZON'\n",
    "df4['SOURCE'] = 'YELP'\n",
    "# df5 already has 'SOURCE'\n",
    "\n",
    "# Add PRODUCT_CATEGORY\n",
    "df4['PRODUCT_CATEGORY'] = 'RESTAURANT'\n",
    "df5['PRODUCT_CATEGORY'] = 'HOTEL'\n",
    "\n",
    "# Standardize column names to uppercase\n",
    "df1.columns = map(str.upper, df1.columns)\n",
    "df2.columns = map(str.upper, df2.columns)\n",
    "df3.columns = map(str.upper, df3.columns)\n",
    "df4.columns = map(str.upper, df4.columns)\n",
    "df5.columns = map(str.upper, df5.columns)\n",
    "\n",
    "# Print header of dataframes\n",
    "print(\"df1 column names:\", df1.columns)\n",
    "print(\"df2 column names:\", df2.columns)\n",
    "print(\"df3 column names:\", df3.columns)\n",
    "print(\"df4 column names:\", df4.columns)\n",
    "print(\"df5 column names:\", df5.columns)\n",
    "\n",
    "# Print number of rows and columns for each dataframe\n",
    "print(\"df1 rows, columns:\", df1.shape)\n",
    "print(\"df2 rows, columns:\", df2.shape)\n",
    "print(\"df3 rows, columns:\", df3.shape) \n",
    "print(\"df4 rows, columns:\", df4.shape)\n",
    "print(\"df5 rows, columns:\", df5.shape)\n",
    "\n",
    "# remove duplicates\n",
    "df1.drop_duplicates(inplace=True)\n",
    "df2.drop_duplicates(inplace=True)\n",
    "df3.drop_duplicates(inplace=True)\n",
    "df4.drop_duplicates(inplace=True)\n",
    "df5.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove rows with empty REVIEW_TEXT\n",
    "df1.dropna(subset=['REVIEW_TEXT'], inplace=True)\n",
    "df2.dropna(subset=['REVIEW_TEXT'], inplace=True)\n",
    "df3.dropna(subset=['REVIEW_TEXT'], inplace=True)\n",
    "df4.dropna(subset=['REVIEW_TEXT'], inplace=True)\n",
    "df5.dropna(subset=['REVIEW_TEXT'], inplace=True)\n",
    "\n",
    "\n",
    "# Analyze Labels\n",
    "print(df1['LABEL'].value_counts())\n",
    "print(df2['LABEL'].value_counts())\n",
    "print(df3['LABEL'].value_counts())\n",
    "print(df4['LABEL'].value_counts())\n",
    "print(df5['LABEL'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Label Mapping and Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PRODUCT_CATEGORY  RATING LABEL  \\\n",
      "0         Sports_and_Outdoors_5     5.0     F   \n",
      "1                Pet_Supplies_5     5.0     F   \n",
      "2  Tools_and_Home_Improvement_5     5.0     F   \n",
      "3              Toys_and_Games_5     4.0     F   \n",
      "4                       Books_5     5.0     F   \n",
      "\n",
      "                                         REVIEW_TEXT  SOURCE  \\\n",
      "0  Does what its suppose to, and it's a very comf...  AMAZON   \n",
      "1  This little vacuum works great.  I have a very...  AMAZON   \n",
      "2  I have two of these and have had no issues. I ...  AMAZON   \n",
      "3  I love this thing. It looks real and the mater...  AMAZON   \n",
      "4  This was purchased for my daughter.  She loves...  AMAZON   \n",
      "\n",
      "  VERIFIED_PURCHASE REVIEW_TITLE PRODUCT_TITLE  \n",
      "0               NaN          NaN           NaN  \n",
      "1               NaN          NaN           NaN  \n",
      "2               NaN          NaN           NaN  \n",
      "3               NaN          NaN           NaN  \n",
      "4               NaN          NaN           NaN  \n",
      "df1 rows, columns: (7960, 8)\n"
     ]
    }
   ],
   "source": [
    "# For the first dataset with 'CG' and 'OR'\n",
    "df1['LABEL'] = df1['LABEL'].map({'CG': 'F', 'OR': 'R'})\n",
    "\n",
    "# For the second dataset with 0.0 and 1.0\n",
    "df2['LABEL'] = df2['LABEL'].map({0.0: 'R', 1.0: 'F'})\n",
    "df2['VERIFIED_PURCHASE'] = df2['VERIFIED_PURCHASE'].map({0.0: 'N', 1.0: 'Y'})\n",
    "\n",
    "# For the third dataset with '__label1__' and '__label2__'\n",
    "df3['LABEL'] = df3['LABEL'].map({'__label1__': 'F', '__label2__': 'R'})\n",
    "\n",
    "# For the fourth dataset with 1 and -1\n",
    "df4['LABEL'] = df4['LABEL'].map({1: 'R', -1: 'F'})\n",
    "\n",
    "# For the fifth dataset with 'truthful' and 'deceptive'\n",
    "df5['LABEL'] = df5['LABEL'].map({'truthful': 'R', 'deceptive': 'F'})\n",
    "\n",
    "# Sample 400 fake reviews from df1 to simulate user feedback, with a consistent random state\n",
    "df_feedback = df1[df1['LABEL'] == 'F'].sample(n=400, random_state=840)\n",
    "\n",
    "# Save final dataset as a CSV file\n",
    "df_feedback.to_csv('user_feedback.csv', index=False)\n",
    "\n",
    "# Exclude these feedback reviews from df1 before further processing\n",
    "df1 = df1.drop(df_feedback.index)\n",
    "\n",
    "# Function to sample 796 real and 796 fake reviews from each dataset with a consistent random state\n",
    "def sample_data(df):\n",
    "    df_fake = df[df['LABEL'] == 'F'].sample(n=796, random_state=840)\n",
    "    df_real = df[df['LABEL'] == 'R'].sample(n=796, random_state=840)\n",
    "    return pd.concat([df_fake, df_real])\n",
    "\n",
    "# Using sampling function on dataframes\n",
    "dfs_to_merge = [df1, df2, df3, df4, df5]\n",
    "sampled_dfs = [sample_data(df) for df in dfs_to_merge]\n",
    "\n",
    "# Merge sampled dataframes\n",
    "final_df = pd.concat(sampled_dfs, ignore_index=True)\n",
    "\n",
    "# save final dataset as a CSV file\n",
    "final_df.to_csv('final_dataset.csv', index=False)\n",
    "\n",
    "# Print header of final dataframe\n",
    "print(final_df.head())\n",
    "\n",
    "# Print number of rows and columns for final dataframe\n",
    "print(\"df1 rows, columns:\", final_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
