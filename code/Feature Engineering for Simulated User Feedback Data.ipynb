{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Feature Engineering for Simulated User Feedback Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Faryad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Faryad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Faryad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "import textstat\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Feature Extraction: Text Length, Sentiment Polarity, and Product Name Mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "user_feedback = pd.read_csv (\"user_feedback.csv\")\n",
    "\n",
    "# Calculate the length of reviews by counting the words in each review and store it as a new feature\n",
    "user_feedback['TEXT_LENGTH'] = user_feedback['REVIEW_TEXT'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Analyze sentiment scores (polarity) of each review using TextBlob and store it as a new feature\n",
    "user_feedback['SENTIMENT_POLARITY'] = user_feedback['REVIEW_TEXT'].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Feature Engineering: Important Words and Repeating Words Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def ratio_repeating_words(text):\n",
    "    # Tokenize the text into words, considering only alphanumeric words\n",
    "    words = [word for word in text.split() if word.isalnum()]\n",
    "    total_word_count = len(words)\n",
    "    # Return 0 if the review is empty or very short to avoid division by zero\n",
    "    if total_word_count <= 1:\n",
    "        return 0\n",
    "\n",
    "    # Create a dictionary to count occurrences of each word\n",
    "    word_counts = {}\n",
    "    for word in words:\n",
    "        word_lowercase = word.lower()\n",
    "        if word_lowercase in word_counts:\n",
    "            word_counts[word_lowercase] += 1\n",
    "        else:\n",
    "            word_counts[word_lowercase] = 1\n",
    "\n",
    "    # Count the number of words that appear more than once\n",
    "    repeating_words_count = sum(1 for count in word_counts.values() if count > 1)\n",
    "\n",
    "    # Calculate the ratio of repeating words to the total word count\n",
    "    ratio = repeating_words_count / total_word_count\n",
    "    return ratio\n",
    "\n",
    "# Apply the function to each review in the dataset to create the new feature\n",
    "user_feedback['RATIO_REPEATING_WORDS'] = user_feedback['REVIEW_TEXT'].apply(ratio_repeating_words)\n",
    "\n",
    "# List of important words\n",
    "important_words = [\"great\", \"love\", \"like\", \"really\", \"quality\", \"good\"]\n",
    "\n",
    "def add_combined_important_words_count(df, words):\n",
    "    df['IMPORTANT_WORDS_COUNT'] = df['REVIEW_TEXT'].apply(lambda x: sum(x.lower().split().count(word) for word in words))\n",
    "    return df\n",
    "\n",
    "# Apply the function\n",
    "user_feedback = add_combined_important_words_count(user_feedback, important_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Calculating Additional Text-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PRODUCT_CATEGORY  RATING LABEL  \\\n",
      "0       Toys_and_Games_5     5.0     F   \n",
      "1        Movies_and_TV_5     5.0     F   \n",
      "2         Pet_Supplies_5     5.0     F   \n",
      "3       Toys_and_Games_5     5.0     F   \n",
      "4  Sports_and_Outdoors_5     5.0     F   \n",
      "\n",
      "                                         REVIEW_TEXT  SOURCE  TEXT_LENGTH  \\\n",
      "0  My children have really enjoyed this set and t...  AMAZON          120   \n",
      "1  This is one of the better ones I've seen in a ...  AMAZON           32   \n",
      "2  Y dogs could eat these, but I thought they wou...  AMAZON           65   \n",
      "3  Omg... this Is a super cute set, the materials...  AMAZON           16   \n",
      "4  I bought a couple of these for my son and they...  AMAZON           38   \n",
      "\n",
      "   SENTIMENT_POLARITY  RATIO_REPEATING_WORDS  IMPORTANT_WORDS_COUNT  \\\n",
      "0            0.235577               0.140187                      3   \n",
      "1            0.364286               0.111111                      0   \n",
      "2           -0.145833               0.186441                      0   \n",
      "3            0.177778               0.153846                      0   \n",
      "4            0.206786               0.114286                      0   \n",
      "\n",
      "   STOPWORDS  FK_SCORE  CAPITALIZATION_COUNT  PUNCTUATION_COUNT  \n",
      "0         72       2.8                    13                 14  \n",
      "1         18       3.6                     5                  5  \n",
      "2         39       4.9                     5                  6  \n",
      "3          8       7.2                     2                  5  \n",
      "4         22       3.5                     3                  3  \n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of stopwords in each review and store it as a new feature\n",
    "stop = set(stopwords.words('english'))\n",
    "user_feedback['STOPWORDS'] = user_feedback['REVIEW_TEXT'].apply(lambda x: len([word for word in word_tokenize(x.lower()) if word in stop]))\n",
    "\n",
    "# Compute the Flesch-Kincaid grade level for each review and store it as a new feature\n",
    "user_feedback['FK_SCORE'] = user_feedback['REVIEW_TEXT'].apply(lambda x: textstat.flesch_kincaid_grade(x))\n",
    "\n",
    "# Count the number of uppercase letters in each review and store it as a new feature\n",
    "user_feedback['CAPITALIZATION_COUNT'] = user_feedback['REVIEW_TEXT'].apply(lambda x: sum(1 for char in x if char.isupper()))\n",
    "\n",
    "# Count the number of punctuation marks in each review and store it as a new feature\n",
    "user_feedback['PUNCTUATION_COUNT'] = user_feedback['REVIEW_TEXT'].apply(lambda x: sum(1 for char in x if char in string.punctuation))\n",
    "\n",
    "# Display the updated DataFrame to verify new features\n",
    "print(user_feedback.head())\n",
    "\n",
    "# Save the modified dataset with new features to a CSV file\n",
    "user_feedback.to_csv('modified_feedback.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
